{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef6304f4-1edc-4bbe-af5a-26dc143759eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets evaluate accelerate --quiet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "import evaluate\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import os, ssl\n",
    "\n",
    "os.environ[\"HF_HUB_DISABLE_SSL_VERIFICATION\"] = \"1\"\n",
    "os.environ[\"CURL_CA_BUNDLE\"] = \"\"\n",
    "os.environ[\"SSL_CERT_FILE\"] = \"\"\n",
    "os.environ[\"REQUESTS_CA_BUNDLE\"] = \"\"\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\", trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4e5db1d-58ee-4e2b-aaea-b639a1952e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'stance', 'input_ids', 'attention_mask'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_json(\"data/PStance/processed/train.jsonl\", lines=True)\n",
    "val_df   = pd.read_json(\"data/PStance/processed/val.jsonl\",   lines=True)\n",
    "test_df  = pd.read_json(\"data/PStance/processed/test.jsonl\",  lines=True)\n",
    "\n",
    "print(train_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "058888e0-c750-4f82-98c9-7e05b45e6366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Stance</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>clean_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i endorse bernie for tons of reasons, but this...</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>i endorse bernie for tons of reasons, but this...</td>\n",
       "      <td>bernie sanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a big problem wbernie left is not only preoccu...</td>\n",
       "      <td>AGAINST</td>\n",
       "      <td>a big problem wbernie left is not only preoccu...</td>\n",
       "      <td>bernie sanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this poll is not reflecting anything: age was ...</td>\n",
       "      <td>AGAINST</td>\n",
       "      <td>this poll is not reflecting anything: age was ...</td>\n",
       "      <td>bernie sanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>so proud how is shedding light on who is truly...</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>so proud how is shedding light on who is truly...</td>\n",
       "      <td>bernie sanders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>according to media bias fact checker, you have...</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>according to media bias fact checker, you have...</td>\n",
       "      <td>bernie sanders</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   Stance  \\\n",
       "0  i endorse bernie for tons of reasons, but this...    FAVOR   \n",
       "1  a big problem wbernie left is not only preoccu...  AGAINST   \n",
       "2  this poll is not reflecting anything: age was ...  AGAINST   \n",
       "3  so proud how is shedding light on who is truly...    FAVOR   \n",
       "4  according to media bias fact checker, you have...    FAVOR   \n",
       "\n",
       "                                         clean_tweet    clean_target  \n",
       "0  i endorse bernie for tons of reasons, but this...  bernie sanders  \n",
       "1  a big problem wbernie left is not only preoccu...  bernie sanders  \n",
       "2  this poll is not reflecting anything: age was ...  bernie sanders  \n",
       "3  so proud how is shedding light on who is truly...  bernie sanders  \n",
       "4  according to media bias fact checker, you have...  bernie sanders  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/PStance/processed/cleaned_pstance.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2faca83-f57e-4143-b0bf-eae6f5cd9951",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\"favor\": 0, \"against\": 1, \"none\": 2}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "# Map stance → numeric\n",
    "for df in (train_df, val_df, test_df):\n",
    "    df[\"labels\"] = df[\"stance\"].str.lower().map(label2id)\n",
    "    df.dropna(subset=[\"labels\"], inplace=True)\n",
    "    df[\"labels\"] = df[\"labels\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "716c68dc-70ae-4810-9c15-150894d02d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "valid_ds = Dataset.from_pandas(val_df)\n",
    "test_ds  = Dataset.from_pandas(test_df)\n",
    "cols_to_keep = [\"input_ids\", \"attention_mask\", \"labels\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff68f5af-384c-4c95-a60d-57e788f89e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 15101/15101 [00:01<00:00, 9507.85 examples/s] \n",
      "Map: 100%|██████████| 3236/3236 [00:00<00:00, 10674.07 examples/s]\n",
      "Map: 100%|██████████| 3237/3237 [00:00<00:00, 5249.20 examples/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Detect text column\n",
    "if \"text\" in train_df.columns:\n",
    "    text_col = \"text\"\n",
    "elif \"tweet\" in train_df.columns:\n",
    "    text_col = \"tweet\"\n",
    "else:\n",
    "    candidates = [c for c in train_df.columns if c not in [\"labels\", \"stance\"]]\n",
    "    text_col = candidates[0]\n",
    "\n",
    "use_target = \"target\" in train_df.columns\n",
    "\n",
    "def tokenize_function(batch):\n",
    "    if use_target:\n",
    "        texts = [f\"{tgt} [SEP] {txt}\" for tgt, txt in zip(batch[\"target\"], batch[text_col])]\n",
    "    else:\n",
    "        texts = batch[text_col]\n",
    "    return tokenizer(texts, truncation=True)\n",
    "\n",
    "train_ds = train_ds.map(tokenize_function, batched=True)\n",
    "valid_ds = valid_ds.map(tokenize_function, batched=True)\n",
    "test_ds  = test_ds.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d2203a0-3cad-475b-9b55-3a8fe467767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep needed columns\n",
    "cols_to_keep = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "train_ds = train_ds.remove_columns([c for c in train_ds.column_names if c not in cols_to_keep])\n",
    "valid_ds = valid_ds.remove_columns([c for c in valid_ds.column_names if c not in cols_to_keep])\n",
    "test_ds  = test_ds.remove_columns([c for c in test_ds.column_names if c not in cols_to_keep])\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3504e348-ca69-409d-be1d-39d86cc9cbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=3,\n",
    "    id2label={0: \"favor\", 1: \"against\", 2: \"none\"},\n",
    "    label2id={\"favor\": 0, \"against\": 1, \"none\": 2},\n",
    ")\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "245dc6b2-d71d-4cd5-9f46-880bde1248ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./roberta_results\",\n",
    "    \n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    # NEW TRANSFORMERS API (4.57.3)\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    logging_strategy=\"steps\",\n",
    "\n",
    "    logging_steps=100,\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "509fd610-a944-4356-b850-40902139a085",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34901/31267686.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=valid_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f8c1a6-210a-44f6-95db-6132a2967eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = trainer.evaluate(test_ds)\n",
    "print(\"Test results:\", test_results)\n",
    "preds = trainer.predict(test_ds)\n",
    "y_true = preds.label_ids\n",
    "y_pred = preds.predictions.argmax(axis=1)\n",
    "cm = confusion_matrix(y_true, y_pred, labels=[0,1,2])\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=[\"favor\",\"against\",\"none\"])\n",
    "disp.plot(values_format=\"d\")\n",
    "plt.title(\"RoBERTa — Confusion Matrix (P-Stance)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e05ff64-4df6-4a0c-b641-bac9a44b0b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS ONLY ONE TIME\n",
    "pred_output = trainer.predict(test_ds)\n",
    "np.save(\"y_true.npy\", pred_output.label_ids)\n",
    "np.save(\"y_pred.npy\", np.argmax(pred_output.predictions, axis=1))\n",
    "print(\"Saved predictions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa96589-490a-46c6-a4aa-f9aa2c3fbfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "# Convert predictions\n",
    "y_true = pred_output.label_ids\n",
    "y_pred = np.argmax(pred_output.predictions, axis=1)\n",
    "\n",
    "# ============================\n",
    "# CLASSIFICATION REPORT VISUAL\n",
    "# ============================\n",
    "\n",
    "report = classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    labels=[0,1,2],\n",
    "    target_names=[\"favor\",\"against\",\"none\"],\n",
    "    output_dict=True,\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "classes = [\"favor\",\"against\",\"none\"]\n",
    "f1_scores = [report[c][\"f1-score\"] for c in classes]\n",
    "precision = [report[c][\"precision\"] for c in classes]\n",
    "recall = [report[c][\"recall\"] for c in classes]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
